/**
 * Base Agent class with agentic loop
 */

import { LLMClient, type LLMMessage } from './llm-client.js';
import { ToolExecutor, type ToolExecutionContext } from '../tools/tool-executor.js';
import type { Tool } from '@anthropic-ai/sdk/resources/messages.mjs';

export interface AgentConfig {
  llm: LLMClient;
  tools: Tool[];
  systemPrompt: string;
  maxIterations?: number;
  context: ToolExecutionContext;
}

export interface AgentResult {
  success: boolean;
  iterations: number;
  finalMessage: string;
  data?: any;
}

export abstract class BaseAgent {
  protected llm: LLMClient;
  protected tools: Tool[];
  protected systemPrompt: string;
  protected maxIterations: number;
  protected executor: ToolExecutor;
  protected messages: LLMMessage[];

  constructor(config: AgentConfig) {
    this.llm = config.llm;
    this.tools = config.tools;
    this.systemPrompt = config.systemPrompt;
    this.maxIterations = config.maxIterations || 50;
    this.executor = new ToolExecutor(config.context);
    this.messages = [];
  }

  /**
   * Main agentic loop
   */
  async run(initialPrompt: string): Promise<AgentResult> {
    console.log(`\nðŸ¤– Starting agent: ${this.constructor.name}`);
    console.log(`ðŸ“‹ Initial task: ${initialPrompt}\n`);

    // Add initial user message
    this.messages.push({
      role: 'user',
      content: initialPrompt
    });

    let iteration = 0;
    let isComplete = false;
    let finalData: any = null;

    while (iteration < this.maxIterations && !isComplete) {
      iteration++;
      console.log(`\nâ”â”â” Iteration ${iteration}/${this.maxIterations} â”â”â”`);

      // Get LLM response
      const response = await this.llm.complete(
        this.messages,
        this.tools,
        this.systemPrompt
      );

      // Log LLM thinking
      if (response.content) {
        console.log(`ðŸ’­ Agent: ${response.content.substring(0, 200)}${response.content.length > 200 ? '...' : ''}`);
      }

      // Check if agent wants to use tools
      if (response.toolCalls && response.toolCalls.length > 0) {
        // Execute tools
        const toolResults = [];

        for (const toolCall of response.toolCalls) {
          console.log(`ðŸ”§ Tool: ${toolCall.name}`);
          console.log(`   Input: ${JSON.stringify(toolCall.input).substring(0, 100)}...`);

          try {
            const result = await this.executor.execute(toolCall.name, toolCall.input);
            toolResults.push(result);

            // Check if this tool signals completion
            if (result.complete) {
              isComplete = true;
              finalData = result;
            }

            console.log(`   âœ“ Result: ${JSON.stringify(result).substring(0, 100)}...`);
          } catch (error: any) {
            console.log(`   âœ— Error: ${error.message}`);
            toolResults.push({ error: error.message });
          }
        }

        // Continue conversation with tool results
        const nextResponse = await this.llm.continueWithToolResults(
          this.messages,
          response.toolCalls,
          toolResults,
          this.tools,
          this.systemPrompt
        );

        // Add assistant message to history
        this.messages.push({
          role: 'assistant',
          content: response.content + (nextResponse.content || '')
        });

        // Check if we're done after processing tool results
        if (isComplete) {
          break;
        }

        // If agent has more to say or more tools to use
        if (nextResponse.toolCalls && nextResponse.toolCalls.length > 0) {
          // Loop will continue to handle more tool calls
          continue;
        } else if (nextResponse.stopReason === 'end_turn') {
          // Agent finished its turn
          break;
        }
      } else {
        // No tool calls, agent finished
        this.messages.push({
          role: 'assistant',
          content: response.content
        });
        break;
      }
    }

    const finalMessage = this.messages[this.messages.length - 1].content;

    console.log(`\nâœ… Agent completed after ${iteration} iterations\n`);

    return {
      success: isComplete || iteration < this.maxIterations,
      iterations: iteration,
      finalMessage,
      data: finalData
    };
  }

  /**
   * Get conversation history
   */
  getMessages(): LLMMessage[] {
    return this.messages;
  }

  /**
   * Reset agent state
   */
  reset(): void {
    this.messages = [];
  }
}
